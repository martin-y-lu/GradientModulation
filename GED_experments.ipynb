{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc00be4-3acb-4948-afde-90b1d358b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c87e415-66fa-4784-a9ce-7f11fed5e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transform\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split into train and val\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "8f796132-7ee4-44d8-b962-4b659a16577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "class GEDReLU5Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, S_n_n, S_n_p, S_p_n, S_p_p, Gi, l, k1, k2, p = 1):\n",
    "        ctx.l = l\n",
    "        ctx.k1 = k1\n",
    "        ctx.k2 = k2\n",
    "        ctx.p = p\n",
    "        ctx.save_for_backward(input, S_n_n, S_n_p, S_p_n, S_p_p, Gi)\n",
    "        return F.relu(input)\n",
    "    # @staticmethod\n",
    "    # def forward(ctx, input):\n",
    "    #     # ctx.l = l\n",
    "    #     # ctx.k = k\n",
    "    #     # ctx.p = p\n",
    "    #     ctx.save_for_backward(input)\n",
    "    #     return F.relu(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, S_n_n, S_n_p, S_p_n, S_p_p, Gi = ctx.saved_tensors\n",
    "\n",
    "        # print(\"---input shape:\", input.shape)\n",
    "        # print(\"S_n_n shape:\", S_n_n.shape)\n",
    "        # print(\"S_n_p shape:\", S_n_p.shape)\n",
    "        # print(\"S_p_n shape:\", S_p_n.shape)\n",
    "        # print(\"S_p_p shape:\", S_p_p.shape)\n",
    "        # print(\"grad_output shape:\", grad_output.shape)\n",
    "\n",
    "\n",
    "        l, k1, k2, p = ctx.l, ctx.k1, ctx.k2, ctx.p\n",
    "\n",
    "        S_n_n = S_n_n.unsqueeze(0)  # [1, C, H, W]\n",
    "        S_n_p = S_n_p.unsqueeze(0)\n",
    "        S_p_n = S_p_n.unsqueeze(0)\n",
    "        S_p_p = S_p_p.unsqueeze(0)\n",
    "        Gi = Gi.unsqueeze(0)\n",
    "        \n",
    "        # Gradient mask and kernel\n",
    "        relu_mask = (input > 0).float()\n",
    "        kernel = torch.where(input*grad_output > 0,\n",
    "            torch.zeros_like(input) if l*k1 == 0 else l / (1 + torch.abs(input) / (l * k1)),\n",
    "            torch.zeros_like(input) if l*k2 == 0 else l / (1 + torch.abs(input) / (l * k2)),\n",
    "        )\n",
    "\n",
    "        # Modulated gradient through activation\n",
    "        grad_input = relu_mask*grad_output\n",
    "        eventual_input = - torch.sign(input) * kernel * grad_output\n",
    "\n",
    "        eps = 1e-12\n",
    "        # Apply gating logic\n",
    "        gated_eventual_input = torch.where(\n",
    "            input < 0,\n",
    "            torch.where(\n",
    "                (S_n_n + S_n_p <= 0) | (eventual_input <= 0),\n",
    "                eventual_input,\n",
    "                eventual_input * (-S_n_n / (S_n_p + eps))\n",
    "            ),\n",
    "            torch.where(\n",
    "                (S_p_p + S_p_n >= 0) | (eventual_input >= 0),\n",
    "                eventual_input,\n",
    "                eventual_input * (S_p_p / (-S_p_n + eps))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        S_n = S_n_n + S_n_p\n",
    "        S_n_c = S_n*(S_n < 0).float()\n",
    "        S_p = S_p_p + S_p_n\n",
    "        S_p_c = S_p*(S_p > 0).float()\n",
    "        \n",
    "        s = min(torch.sum(Gi*(S_n_c+ S_p_c))/(torch.sum(Gi*Gi)+ eps),0)\n",
    "        \n",
    "        gated_grad_input = grad_input *(1 - s)\n",
    "\n",
    "        grad_S_n_n = (((input < 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_n_p = (((input < 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_p_n = (((input > 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_p_p = (((input > 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "\n",
    "        return gated_grad_input + gated_eventual_input*p, grad_S_n_n, grad_S_n_p, grad_S_p_n, grad_S_p_p, eventual_input, None, None, None, None\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GEDReLU5(nn.Module):\n",
    "    def __init__(self, shape = None, l=0.01, k1=1, k2= 1.0, p=1.0):\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.p = p\n",
    "        self.is_GED = True\n",
    "\n",
    "        if shape != None:\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_p_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_p_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.S_p_n.is_GED = True\n",
    "            self.S_p_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        else:\n",
    "            self.S_n_n = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        # # Lazy init on first call\n",
    "        if self.S_n_n is None:\n",
    "            shape = input.shape[1:]  # Exclude batch dim\n",
    "            device = input.device\n",
    "            dtype = input.dtype\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_p_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_p_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.S_p_n.is_GED = True\n",
    "            self.S_p_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        return GEDReLU5Function.apply(input, self.S_n_n, self.S_n_p, self.S_p_n, self.S_p_p, self.Gi, self.l, self.k1, self.k2, self.p)\n",
    "        # return GEDReLUFunction.apply(input)\n",
    "\n",
    "    def update_s(self, beta=0.9):\n",
    "        \"\"\"\n",
    "        Manual update rule, called every epoch.\n",
    "        Implements EMA-like update:\n",
    "        S := beta * S + (1 - beta) * grad_S\n",
    "        \"\"\"\n",
    "        for param in [self.S_n_n, self.S_n_p, self.S_p_n, self.S_p_p, self.Gi]:\n",
    "            if param.grad is not None:\n",
    "                param.data.mul_(beta).add_((1 - beta) * param.grad.data)\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()\n",
    "\n",
    "    def get_s_buffers(self):\n",
    "        return {\n",
    "            \"S_n_n\": self.S_n_n,\n",
    "            \"S_n_p\": self.S_n_p,\n",
    "            \"S_p_n\": self.S_p_n,\n",
    "            \"S_p_p\": self.S_p_p\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7ff20d2b-329d-41e9-b699-22bed7e890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "class GEDGELUFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, S_n_n, S_n_p, Gi, l, k1, k2, p = 1):\n",
    "        ctx.l = l\n",
    "        ctx.k1 = k1 \n",
    "        ctx.k2 = k2\n",
    "        ctx.p = p\n",
    "        ctx.save_for_backward(input, S_n_n, S_n_p, Gi)\n",
    "        return F.gelu(input)\n",
    "    # @staticmethod\n",
    "    # def forward(ctx, input):\n",
    "    #     # ctx.l = l\n",
    "    #     # ctx.k = k\n",
    "    #     # ctx.p = p\n",
    "    #     ctx.save_for_backward(input)\n",
    "    #     return F.relu(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, S_n_n, S_n_p, Gi = ctx.saved_tensors\n",
    "\n",
    "        # print(\"---input shape:\", input.shape)\n",
    "        # print(\"S_n_n shape:\", S_n_n.shape)\n",
    "        # print(\"S_n_p shape:\", S_n_p.shape)\n",
    "        # print(\"S_p_n shape:\", S_p_n.shape)\n",
    "        # print(\"S_p_p shape:\", S_p_p.shape)\n",
    "        # print(\"grad_output shape:\", grad_output.shape)\n",
    "\n",
    "\n",
    "        l, k1, k2, p = ctx.l, ctx.k1, ctx.k2, ctx.p\n",
    "\n",
    "        S_n_n = S_n_n.unsqueeze(0)  # [1, C, H, W]\n",
    "        S_n_p = S_n_p.unsqueeze(0)\n",
    "        Gi = Gi.unsqueeze(0)\n",
    "        \n",
    "        # Gradient mask and kernel\n",
    "        gelu_mask = 0.5*(torch.erf(input/np.sqrt(2))+1) + input/np.sqrt(2*np.pi)*torch.exp(-input*input/2)\n",
    "        v = 0.6\n",
    "        kernel = torch.where(input*grad_output > 0,\n",
    "            torch.zeros_like(input) if l*k1 == 0 else l*v*input / (1 + torch.abs(input*input*v*v) / (k1)),\n",
    "            torch.zeros_like(input) if l*k2 == 0 else l*v*input / (1 + torch.abs(input*input*v*v) / (k2)),\n",
    "        )\n",
    "\n",
    "        # Modulated gradient through activation\n",
    "        grad_input = gelu_mask*grad_output\n",
    "        eventual_input = (input < 0).float() * kernel * grad_output\n",
    "\n",
    "        eps = 1e-12\n",
    "        # Apply gating logic\n",
    "        gated_eventual_input = torch.where((eventual_input <= 0)| (S_n_n + S_n_p <= 0),\n",
    "                    eventual_input,\n",
    "                    eventual_input * (-S_n_n / (S_n_p + eps)),\n",
    "                )\n",
    "\n",
    "        S_n = S_n_n + S_n_p\n",
    "        S_n_c = S_n*(S_n< 0).float()\n",
    "        s = min(torch.sum(Gi*S_n_c)/(torch.sum(Gi*Gi)+ eps),0)\n",
    "        \n",
    "        gated_grad_input = grad_input *(1 - s)\n",
    "        # gated_grad_input = grad_input *( 1 + torch.where((S_n_n + S_n_p < 0) & (Gi > 0), -(S_n_n + S_n_p)/Gi, 0))\n",
    "\n",
    "        grad_S_n_n = (((input < 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_n_p = (((input < 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "\n",
    "        return gated_grad_input + gated_eventual_input, grad_S_n_n, grad_S_n_p, grad_input , None, None, None, None, None\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GEDGELU(nn.Module):\n",
    "    def __init__(self, shape = None, l=0.01, k1=1, k2 = 1, p=1.0):\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.p = p\n",
    "        self.is_GED = True\n",
    "\n",
    "        if shape != None:\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        else:\n",
    "            self.S_n_n = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        # # Lazy init on first call\n",
    "        if self.S_n_n is None:\n",
    "            shape = input.shape[1:]  # Exclude batch dim\n",
    "            device = input.device\n",
    "            dtype = input.dtype\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        return GEDGELUFunction.apply(input, self.S_n_n, self.S_n_p, self.Gi, self.l, self.k1, self.k2, self.p)\n",
    "        # return GEDReLUFunction.apply(input)\n",
    "\n",
    "    def update_s(self, beta=0.9):\n",
    "        \"\"\"\n",
    "        Manual update rule, called every epoch.\n",
    "        Implements EMA-like update:\n",
    "        S := beta * S + (1 - beta) * grad_S\n",
    "        \"\"\"\n",
    "        for param in [self.S_n_n, self.S_n_p, self.Gi]:\n",
    "            if param.grad is not None:\n",
    "                param.data.mul_(beta).add_((1 - beta) * param.grad.data)\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()\n",
    "\n",
    "    def get_s_buffers(self):\n",
    "        return {\n",
    "            \"S_n_n\": self.S_n_n,\n",
    "            \"S_n_p\": self.S_n_p,\n",
    "            \"S_p_n\": self.S_p_n,\n",
    "            \"S_p_p\": self.S_p_p\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fe1ff932-1e21-4600-b2ac-544b0a0636e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,1])\n",
    "b = torch.tensor([-1,-1])\n",
    "#increase magnitude of a by magnitude of b projected onto a\n",
    "s =  min(torch.sum(a*b)/torch.sum(a*a),0)\n",
    "ae = a*( 1-s)\n",
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6e4a043e-12a5-4729-a1dc-5ce12bc62f78",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cmin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmin\u001b[49m(torch\u001b[38;5;241m.\u001b[39mrand([\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m]),\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/__init__.py:1938\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 1938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cmin'"
     ]
    }
   ],
   "source": [
    "torch.cmin(torch.rand([10,10]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f92bd316-a30c-414d-b9de-70f1377e0523",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tensordot expects dims < ndim_a or ndim_b, but got dims=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/functional.py:1203\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, dims, out)\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensordot expects dims >= 0, but got dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mmin\u001b[39m(a\u001b[38;5;241m.\u001b[39mdim(), b\u001b[38;5;241m.\u001b[39mdim()):\n\u001b[0;32m-> 1203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensordot expects dims < ndim_a or ndim_b, but got dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1204\u001b[0m dims_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39mdims, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m   1205\u001b[0m dims_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(dims))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensordot expects dims < ndim_a or ndim_b, but got dims=2"
     ]
    }
   ],
   "source": [
    "torch.tensordot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502793e8-db9e-4d01-a1ba-f2ec008a9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensordot(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a182d2ba-f3ce-4024-864b-f90070d604bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEDCNN(nn.Module):\n",
    "    def __init__(self, l=0.01, k1=5.0, k2 = 1.0, act_class = GEDReLU,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.relu4 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layerv\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        for module in self.children():\n",
    "            if hasattr(module,\"is_GED\"):\n",
    "                module.update_s(beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = self.pool(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8811bd95-3bbb-4f80-8fda-d1739ade442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEDGELUCNN(nn.Module):\n",
    "    def __init__(self, l=0.01, k1=5.0, k2 = 1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.relu4 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layerv\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        for module in self.children():\n",
    "            if hasattr(module,\"is_GED\"):\n",
    "                module.update_s(beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = self.pool(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "29aec455-52bd-4ab6-b916-465cab5a96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation_fn=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.activation = activation_fn\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = self.pool(self.activation(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e26d9b-e8ba-4f51-b0d7-b182f601d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7597c441-7792-437d-b8fe-805c999ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Train import train_and_evaluate, validate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67b57d7-eebb-4015-81b3-8ef4757a431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_ged(network, train_loader, val_loader, epochs=10, lr=0.001,beta = 0.99, log_every=100, device='cpu',\n",
    "                       save_path = None, save_every = 5, use_ged = True,\n",
    "                       logger = None):\n",
    "    model = network.to(device)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: not hasattr(p,\"is_GED\"), model.parameters()), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    logs = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        grad_norms = []\n",
    "        weight_updates = []\n",
    "        \n",
    "        running_loss = deque(maxlen=50)  # For smooth display\n",
    "        running_acc = deque(maxlen=50)\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "        \n",
    "            # Gradients and updates\n",
    "            total_norm = 0\n",
    "            weight_update_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    total_norm += p.grad.data.norm(2).item() ** 2\n",
    "                    weight_update_norm += (lr * p.grad.data).norm(2).item() ** 2\n",
    "        \n",
    "            grad_norms.append(np.sqrt(total_norm))\n",
    "            weight_updates.append(np.sqrt(weight_update_norm))\n",
    "        \n",
    "            optimizer.step()\n",
    "            if use_ged:\n",
    "                model.update_s(beta)\n",
    "        \n",
    "            batch_size = inputs.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total += batch_size\n",
    "        \n",
    "            batch_acc = (outputs.argmax(1) == labels).float().mean().item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "            # if batch_idx % log_every == 0:\n",
    "            #     logs['batches'].append({\n",
    "            #         'epoch': epoch,\n",
    "            #         'batch_idx': batch_idx,\n",
    "            #         'loss': loss.item(),\n",
    "            #         'acc': batch_acc,\n",
    "            #         'grad_norm': grad_norms[-1],\n",
    "            #         'weight_update_norm': weight_updates[-1],\n",
    "            #         'samples_seen': total\n",
    "            #     })\n",
    "        \n",
    "            # Track running stats for display\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(batch_acc)\n",
    "        \n",
    "            if batch_idx % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{np.mean(running_loss):.4f}',\n",
    "                    'acc': f'{np.mean(running_acc) * 100:.2f}%',\n",
    "                    'grad_norm': f'{grad_norms[-1]:.2f}'\n",
    "                })\n",
    "\n",
    "        logs['train_loss'].append(total_loss / total)\n",
    "        logs['train_acc'].append(correct / total)\n",
    "        logs['train_grad_norm'].append(np.mean(grad_norms))\n",
    "        logs['train_weight_update_norm'].append(np.mean(weight_updates))\n",
    "        \n",
    "        val_loss, val_acc = validate_model(model,val_loader,device)\n",
    "        \n",
    "        logs['val_loss'].append(val_loss)\n",
    "        logs['val_acc'].append(val_acc)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {logs['train_loss'][-1]:.4f} | \"\n",
    "              f\"Train Acc: {logs['train_acc'][-1]*100:.2f}% | \"\n",
    "              f\"Val Acc: {logs['val_acc'][-1]*100:.2f}%\")\n",
    "    return logs, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef305a7-ca00-4e57-a585-5be4120a65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = dict()\n",
    "model_data = dict()\n",
    "def insert_log_data(key,data):\n",
    "    if key not in log_data:\n",
    "        log_data[key] = []\n",
    "    log_data[key].append(data)\n",
    "def insert_model_data(key,data):\n",
    "    if key not in log_data:\n",
    "        model_data[key] = []\n",
    "    model_data[key].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84bebcef-2d80-4156-be6f-d830295d9b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGEDResNet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241m.\u001b[39mreload(GEDResNet)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGEDResNet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GEDResNet18, initialize_ged_resnet\n",
      "\u001b[0;31mNameError\u001b[0m: name 'importlib' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import GEDResNet\n",
    "importlib.reload(GEDResNet)\n",
    "from GEDResNet import GEDResNet18, initialize_ged_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "915400de-b5bf-4356-aed9-dca1daffdb2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.6044 | Train Acc: 42.55% | Val Acc: 49.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.1996 | Train Acc: 57.17% | Val Acc: 56.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 1.0480 | Train Acc: 63.18% | Val Acc: 65.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.9478 | Train Acc: 66.85% | Val Acc: 65.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.8754 | Train Acc: 69.46% | Val Acc: 68.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.8212 | Train Acc: 71.33% | Val Acc: 71.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7745 | Train Acc: 73.13% | Val Acc: 70.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.7401 | Train Acc: 74.13% | Val Acc: 74.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.7099 | Train Acc: 75.47% | Val Acc: 73.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6796 | Train Acc: 76.56% | Val Acc: 73.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.6568 | Train Acc: 77.11% | Val Acc: 75.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.6431 | Train Acc: 77.47% | Val Acc: 75.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.6176 | Train Acc: 78.52% | Val Acc: 75.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.6019 | Train Acc: 79.19% | Val Acc: 76.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.5923 | Train Acc: 79.31% | Val Acc: 77.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5715 | Train Acc: 80.12% | Val Acc: 77.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5594 | Train Acc: 80.54% | Val Acc: 76.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.5553 | Train Acc: 80.48% | Val Acc: 77.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.5361 | Train Acc: 81.30% | Val Acc: 78.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.5296 | Train Acc: 81.54% | Val Acc: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.5120 | Train Acc: 82.06% | Val Acc: 78.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.5044 | Train Acc: 82.43% | Val Acc: 78.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.5003 | Train Acc: 82.49% | Val Acc: 78.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.4890 | Train Acc: 82.90% | Val Acc: 78.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.4789 | Train Acc: 83.18% | Val Acc: 77.62%\n"
     ]
    }
   ],
   "source": [
    "#Test clipped gmodrelu\n",
    "import GModReLU\n",
    "import importlib\n",
    "importlib.reload(GModReLU)\n",
    "from GModReLU import GModReLU, GModReLUFunction\n",
    "loaded_model = CNN(GModReLU(l = l_val, k = k_val, kernel_type = [\"nonscale\",\"clip\"]))\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "l_val = 0.02\n",
    "k_val = 5.0\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gmrelu(nonscale,clip)\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5e7e4202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.5697 | Train Acc: 43.82% | Val Acc: 52.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 1.1664 | Train Acc: 58.77% | Val Acc: 61.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 1.0040 | Train Acc: 64.60% | Val Acc: 65.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.8979 | Train Acc: 68.73% | Val Acc: 68.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.8308 | Train Acc: 71.03% | Val Acc: 69.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.7761 | Train Acc: 72.93% | Val Acc: 73.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.7310 | Train Acc: 74.39% | Val Acc: 73.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.6951 | Train Acc: 75.83% | Val Acc: 75.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.6742 | Train Acc: 76.51% | Val Acc: 74.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.6400 | Train Acc: 77.67% | Val Acc: 76.08%\n"
     ]
    }
   ],
   "source": [
    "#Testting new clipped dged\n",
    "l_val = 0.02\n",
    "k1_val = 7.5\n",
    "k2_val = 0.5\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"ged4\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8a95fc8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11 | Train Loss: 1.5426 | Train Acc: 44.56% | Val Acc: 54.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/11 | Train Loss: 1.1422 | Train Acc: 59.39% | Val Acc: 62.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/11 | Train Loss: 0.9908 | Train Acc: 65.09% | Val Acc: 66.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/11 | Train Loss: 0.8910 | Train Acc: 68.78% | Val Acc: 69.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/11 | Train Loss: 0.8207 | Train Acc: 71.20% | Val Acc: 68.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/11 | Train Loss: 0.7730 | Train Acc: 72.93% | Val Acc: 71.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/11 | Train Loss: 0.7318 | Train Acc: 74.42% | Val Acc: 73.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/11 | Train Loss: 0.6935 | Train Acc: 75.62% | Val Acc: 72.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/11 | Train Loss: 0.6647 | Train Acc: 76.88% | Val Acc: 74.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/11 | Train Loss: 0.6408 | Train Acc: 77.62% | Val Acc: 74.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/11 | Train Loss: 0.6206 | Train Acc: 78.21% | Val Acc: 77.10%\n"
     ]
    }
   ],
   "source": [
    "#Testting GED5\n",
    "#Conclusion: Not significantly better\n",
    "l_val = 0.02\n",
    "k1_val = 7.5\n",
    "k2_val = 0.5\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val, act_class = GEDReLU5)\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=11,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"ged5\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1047e02-4faf-453c-80b0-5529910c09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7:   8%|         | 55/704 [00:21<03:05,  3.50it/s, loss=2.2967, acc=22.59%, grad_norm=3.67] "
     ]
    }
   ],
   "source": [
    "#Testting new clipped dged GELU with new kernel\n",
    "l_val = 0.02\n",
    "k1_val = 7.5\n",
    "k2_val = 0.1\n",
    "loaded_model = GEDGELUCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=7,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gedgelu(ker3)\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248921e-5e56-46ed-ae53-9a72cd82d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "98ccd4cb-fdea-4aeb-a882-c66a38b2c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4848653153101603,\n",
       " 1.0595959030363296,\n",
       " 0.9035886674775018,\n",
       " 0.8083200914700825,\n",
       " 0.7512857806735569,\n",
       " 0.7062555783238675,\n",
       " 0.6603865298165216,\n",
       " 0.636535771730211,\n",
       " 0.6080090568860372,\n",
       " 0.5905408076816135,\n",
       " 0.5694922658390469,\n",
       " 0.5512248729652829,\n",
       " 0.5357832288821538,\n",
       " 0.5198717035690943,\n",
       " 0.5023744517220391,\n",
       " 0.4949553271823459,\n",
       " 0.4873157972070906,\n",
       " 0.4778727073113124,\n",
       " 0.4646957883516947,\n",
       " 0.4595615298377143,\n",
       " 0.4511569716135661,\n",
       " 0.44614050909678143,\n",
       " 0.4364197584470113,\n",
       " 0.4325642474386427,\n",
       " 0.4244985025617811]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data[('ged4', 0.02, 7.5, 0.1)][1]['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "127aede4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.5801 | Train Acc: 43.58% | Val Acc: 51.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.2040 | Train Acc: 56.97% | Val Acc: 58.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 1.0430 | Train Acc: 63.01% | Val Acc: 63.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.9478 | Train Acc: 66.89% | Val Acc: 68.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.8820 | Train Acc: 69.12% | Val Acc: 68.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.8245 | Train Acc: 71.15% | Val Acc: 69.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7818 | Train Acc: 72.77% | Val Acc: 71.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.7408 | Train Acc: 73.97% | Val Acc: 70.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.7260 | Train Acc: 74.71% | Val Acc: 73.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6964 | Train Acc: 75.87% | Val Acc: 74.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.6773 | Train Acc: 76.35% | Val Acc: 75.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.6525 | Train Acc: 77.41% | Val Acc: 75.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.6334 | Train Acc: 77.96% | Val Acc: 74.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.6165 | Train Acc: 78.58% | Val Acc: 74.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.6027 | Train Acc: 78.91% | Val Acc: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5918 | Train Acc: 79.34% | Val Acc: 76.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5805 | Train Acc: 79.68% | Val Acc: 77.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.5655 | Train Acc: 80.23% | Val Acc: 77.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.5549 | Train Acc: 80.75% | Val Acc: 77.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.5534 | Train Acc: 80.61% | Val Acc: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.5391 | Train Acc: 81.28% | Val Acc: 78.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.5293 | Train Acc: 81.52% | Val Acc: 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.5224 | Train Acc: 81.76% | Val Acc: 77.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.5161 | Train Acc: 82.21% | Val Acc: 78.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.5088 | Train Acc: 82.23% | Val Acc: 79.36%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"relu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2d0777c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.5255 | Train Acc: 45.46% | Val Acc: 56.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.1173 | Train Acc: 60.34% | Val Acc: 58.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 0.9623 | Train Acc: 65.89% | Val Acc: 68.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.8570 | Train Acc: 69.96% | Val Acc: 69.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.7964 | Train Acc: 71.95% | Val Acc: 71.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.7401 | Train Acc: 74.11% | Val Acc: 72.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7033 | Train Acc: 75.38% | Val Acc: 73.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.6707 | Train Acc: 76.53% | Val Acc: 74.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.6398 | Train Acc: 77.68% | Val Acc: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6161 | Train Acc: 78.47% | Val Acc: 75.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.5971 | Train Acc: 79.02% | Val Acc: 76.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.5782 | Train Acc: 79.72% | Val Acc: 77.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.5629 | Train Acc: 80.35% | Val Acc: 77.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.5511 | Train Acc: 80.73% | Val Acc: 77.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.5269 | Train Acc: 81.54% | Val Acc: 77.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5115 | Train Acc: 82.08% | Val Acc: 78.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5055 | Train Acc: 82.18% | Val Acc: 78.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.4950 | Train Acc: 82.62% | Val Acc: 78.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.4895 | Train Acc: 82.76% | Val Acc: 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.4755 | Train Acc: 83.17% | Val Acc: 78.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.4653 | Train Acc: 83.69% | Val Acc: 79.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.4523 | Train Acc: 84.08% | Val Acc: 78.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.4431 | Train Acc: 84.46% | Val Acc: 78.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.4388 | Train Acc: 84.52% | Val Acc: 79.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.4330 | Train Acc: 84.84% | Val Acc: 79.06%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = CNN(torch.nn.GELU())\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gelu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a7108d6-1ca7-42d0-b1ee-66d82b9f178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN().state_dict(), \"cnn_untrained1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6727c088-8e64-4198-80a3-7951548e7f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.4478 | Train Acc: 84.58% | Val Acc: 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val)\n\u001b[1;32m      5\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 6\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pt]dged(0.9)\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k1_val,k2_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 47\u001b[0m, in \u001b[0;36mGEDReLUFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Modulated gradient through activation\u001b[39;00m\n\u001b[1;32m     46\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m relu_mask\u001b[38;5;241m*\u001b[39mgrad_output\n\u001b[0;32m---> 47\u001b[0m eventual_input \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m kernel \u001b[38;5;241m*\u001b[39m grad_output\n\u001b[1;32m     49\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Apply gating logic\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.05\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    beta = 0.9,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]dged(0.9)\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a9a2ccfb-0818-493b-b94f-ea79ba843632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 | Train Loss: 0.4429 | Train Acc: 84.50% | Val Acc: 84.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6 | Train Loss: 0.4382 | Train Acc: 84.72% | Val Acc: 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6 | Train Loss: 0.4305 | Train Acc: 84.87% | Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6 | Train Loss: 0.4176 | Train Acc: 85.37% | Val Acc: 84.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6 | Train Loss: 0.4267 | Train Acc: 85.15% | Val Acc: 83.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6 | Train Loss: 0.4129 | Train Acc: 85.48% | Val Acc: 83.48%\n"
     ]
    }
   ],
   "source": [
    "#Testing on pretrained to 35 epochs (focusing in on a particular training regime)\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=6,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]relu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4268fbfd-fc2b-43e5-b30f-a354d867e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35 | Train Loss: 0.4446 | Train Acc: 84.61% | Val Acc: 83.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35 | Train Loss: 0.4368 | Train Acc: 84.80% | Val Acc: 85.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35 | Train Loss: 0.4320 | Train Acc: 84.89% | Val Acc: 84.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35 | Train Loss: 0.4225 | Train Acc: 85.26% | Val Acc: 84.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35 | Train Loss: 0.4145 | Train Acc: 85.57% | Val Acc: 84.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35 | Train Loss: 0.4151 | Train Acc: 85.55% | Val Acc: 82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35 | Train Loss: 0.4108 | Train Acc: 85.57% | Val Acc: 84.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val)\n\u001b[1;32m      6\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 7\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pt]bged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[183], line 63\u001b[0m, in \u001b[0;36mGEDReLUFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     60\u001b[0m gated_grad_input \u001b[38;5;241m=\u001b[39m grad_input \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m s)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# gated_grad_input = grad_input *( 1 + torch.where((S_n_n + S_n_p < 0) & (Gi > 0), -(S_n_n + S_n_p)/Gi, 0))\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m grad_S_n_n \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43meventual_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m eventual_input)\u001b[38;5;241m.\u001b[39msum(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     64\u001b[0m grad_S_n_p \u001b[38;5;241m=\u001b[39m (((\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (eventual_input \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m eventual_input)\u001b[38;5;241m.\u001b[39msum(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gated_grad_input \u001b[38;5;241m+\u001b[39m gated_eventual_input, grad_S_n_n, grad_S_n_p, grad_input , \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testing GED on pretrained to 35 epochs (focusing in on a particular training regime)\n",
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.0\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=35,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]bged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ef8659ae-4b93-4b42-b1d2-009443de84dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1503e-07, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(model.relu1.S_n_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5a4b3876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[278], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m l_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      3\u001b[0m k_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGEDResNet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialize_ged_resnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[resnet]ged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[54], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     21\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ai/GradientModulation/GEDResNet.py:114\u001b[0m, in \u001b[0;36mGEDResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m--> 114\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m    116\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(out)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ai/GradientModulation/GEDResNet.py:35\u001b[0m, in \u001b[0;36mGEDBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n\u001b[1;32m     37\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test GEDResNet\n",
    "l_val = 0.01\n",
    "k_val = 1.0\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = GEDResNet18().apply(initialize_ged_resnet),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=15,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[resnet]ged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf11604-5fe2-4d94-9f79-a6691f46ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1a15156-432b-425b-a09a-afec5efdf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m l_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      3\u001b[0m k_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGEDCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ml_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[54], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    l_val = 0.01\n",
    "    k_val = 5.0\n",
    "    log, model = train_and_evaluate_ged(\n",
    "        network = GEDCNN(l = l_val, k = k_val),\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=2,          # or however many you want\n",
    "        lr=0.001,           # or your preferred LR\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    insert_log_data((\"ged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "626506d6-9e6a-4d59-a917-3369d5dda3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data[('gedgelu', 0.02, 7.5, 0.1)] = [log_data[('ged4', 0.02, 7.5, 0.1)][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bc6b857b-6c06-4855-b592-5dbc4d315dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss shape: (6,)\n",
      "loss shape: (25,)\n",
      "loss shape: (25,)\n",
      "loss shape: (11,)\n",
      "loss shape: (7,)\n",
      "loss shape: (25,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import Figures\n",
    "importlib.reload(Figures)\n",
    "from Figures import log_data_with_k, plot_logs_k, plot_logs_ke, log_data_with_l , plot_logs_k_col, log_data_with_activations\n",
    "prop = \"train_grad_norm\"\n",
    "plot_logs_k_col(*log_data_with_activations([('relu',),('ged5', 0.02, 7.5, 0.5),(\"gelu\",),('gedgelu', 0.02, 7.5, 0.1), ('gedgelu(ker2)', 0.02, 7.5, 0.1)],\n",
    "                                           [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\"], log_data),\n",
    "                file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,20), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',),('ged4', 0.02, 1.0, 0.0),('ged4', 0.02, 5.0, 0.1), ('gmrelu(nonscale,clip)', 0.02, 5.0),(\"gelu\",),('ged4', 0.02, 7.5, 0.1)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (5,25), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',),('gmrelu(nonscale,clip)', 0.02, 1.0),('gmrelu(nonscale)', 0.02, 1.0), ('ged2', 0.02, 1.0, 0.0),('ged4', 0.02, 1.0, 0.0)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (1,6), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',), ('gmrelu(nonscale)', 0.02, 1.0),('gmrelu(nonscale,clip)', 0.02, 1.0),('dged', 0.02, 1.0, 0.5),('dged', 0.02, 1.0, 0.1)\n",
    "#     , ('dged', 0.02, 1.0, 0.0)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (1,4), y_scale = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2cb13ad2-6cad-45d9-8fad-d2fe5ffff02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('relu',), ('gmrelu(nonscale)', 0.02, 1.0), ('gmrelu(nonscale,clip)', 0.02, 1.0), ('dged', 0.02, 1.0, 0.5), ('dged', 0.02, 1.0, 0.1), ('dged', 0.02, 1.0, 0.0), ('dged(0.9)', 0.02, 1.0, 0.0), ('ged', 0.02, 1.0, 0.0), ('ged2', 0.02, 1.0, 0.0), ('ged4', 0.02, 1.0, 0.0), ('[pt]relu',), ('ged4', 0.02, 5.0, 0.1), ('gmrelu(nonscale,clip)', 0.02, 5.0), ('gelu',), ('ged4', 0.02, 7.5, 0.1), ('ged5', 0.02, 7.5, 0.5), ('ged4', 0.02, 7.5, 0.5), ('gedgelu(ker2)', 0.02, 7.5, 0.1)])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a5497b54-60f7-4b9c-b15d-aad32d13919a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFigures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_data_with_k, plot_logs_k, plot_logs_ke, log_data_with_l , plot_logs_k_col, log_data_with_activations\n\u001b[1;32m      5\u001b[0m prop \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m plot_logs_k_col(\u001b[38;5;241m*\u001b[39m\u001b[43mlog_data_with_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgmrelu(noscale)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdged(0.9)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpurple\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_data\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m                 file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,prop \u001b[38;5;241m=\u001b[39m prop, x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,i_cut \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, e_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m), y_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# plot_logs_k_col(*log_data_with_activations([ ('relu',), ('ged', 0.01, 5.0),('ged',0.01,1.0),('ged',0.01,0.5)],[\"red\",\"blue\",\"cyan\",\"green\"], log_data),\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,5 ), y_scale = \"log\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# plot_logs_k_col(*log_data_with_activations([ ('relu',),('ged', 0.0, 5.0),('ged',0.005,5.0), ('ged', 0.01, 5.0),('ged',0.02,5.0)],[\"red\",\"orange\",\"purple\",\"blue\",\"cyan\"], log_data),\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,15), y_scale = \"log\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ai/GradientModulation/Figures.py:96\u001b[0m, in \u001b[0;36mlog_data_with_activations\u001b[0;34m(acts, colors, log_data)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, logs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(logs):\n\u001b[1;32m     95\u001b[0m     logs_flat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logs\n\u001b[0;32m---> 96\u001b[0m     keys_flat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43macts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(logs)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logs_flat, keys_flat\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import Figures\n",
    "importlib.reload(Figures)\n",
    "from Figures import log_data_with_k, plot_logs_k, plot_logs_ke, log_data_with_l , plot_logs_k_col, log_data_with_activations\n",
    "prop = \"train_grad_norm\"\n",
    "plot_logs_k_col(*log_data_with_activations([ ('relu',),('gmrelu(noscale)', 0.02, 1.0),('dged', 0.01, 5.0, 5.0),('dged', 0.01, 1.0, 0.5),('dged(0.9)', 0.02, 1.0, 0.0)],[\"red\",\"orange\",\"blue\",\"purple\",], log_data),\n",
    "                file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,10), y_scale = \"log\")\n",
    "# plot_logs_k_col(*log_data_with_activations([ ('relu',), ('ged', 0.01, 5.0),('ged',0.01,1.0),('ged',0.01,0.5)],[\"red\",\"blue\",\"cyan\",\"green\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,5 ), y_scale = \"log\")\n",
    "# plot_logs_k_col(*log_data_with_activations([ ('relu',),('ged', 0.0, 5.0),('ged',0.005,5.0), ('ged', 0.01, 5.0),('ged',0.02,5.0)],[\"red\",\"orange\",\"purple\",\"blue\",\"cyan\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,15), y_scale = \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e08d8-5036-46a2-bb2c-dca2230eefd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f6e22f1b-bcda-43a7-9e55-fe158281ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "del log_data[('ged', 0.0, 5.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7776a5e5-bada-4d01-9751-671102101a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ged_model = GEDCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "24157b91-8c46-4ec9-8a05-dbbb2cf5555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GEDCNN(\n",
       "   (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (relu1): GEDReLU()\n",
       "   (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (relu2): GEDReLU()\n",
       "   (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (relu3): GEDReLU()\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "   (relu4): GEDReLU()\n",
       "   (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       " ),\n",
       " Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " GEDReLU(),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " GEDReLU(),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " GEDReLU(),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Linear(in_features=2048, out_features=128, bias=True),\n",
       " GEDReLU(),\n",
       " Linear(in_features=128, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ged_model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d1f0d467-aa53-47d1-9735-4b63603cc07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c943f41b-c22d-4f8e-aa71-669edbf31c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda p: not hasattr(p,\"is_GED\"), ged_model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95e9e8-c731-4de9-9906-f3eb526c0f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

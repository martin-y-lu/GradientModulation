{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc00be4-3acb-4948-afde-90b1d358b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c87e415-66fa-4784-a9ce-7f11fed5e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transform\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split into train and val\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acddf96c-7945-451f-b2d9-e8be78823430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GEDReLU4 import GEDReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f796132-7ee4-44d8-b962-4b659a16577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "class GEDReLU5Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, S_n_n, S_n_p, S_p_n, S_p_p, Gi, l, k1, k2, p = 1):\n",
    "        ctx.l = l\n",
    "        ctx.k1 = k1\n",
    "        ctx.k2 = k2\n",
    "        ctx.p = p\n",
    "        ctx.save_for_backward(input, S_n_n, S_n_p, S_p_n, S_p_p, Gi)\n",
    "        return F.relu(input)\n",
    "    # @staticmethod\n",
    "    # def forward(ctx, input):\n",
    "    #     # ctx.l = l\n",
    "    #     # ctx.k = k\n",
    "    #     # ctx.p = p\n",
    "    #     ctx.save_for_backward(input)\n",
    "    #     return F.relu(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, S_n_n, S_n_p, S_p_n, S_p_p, Gi = ctx.saved_tensors\n",
    "\n",
    "        # print(\"---input shape:\", input.shape)\n",
    "        # print(\"S_n_n shape:\", S_n_n.shape)\n",
    "        # print(\"S_n_p shape:\", S_n_p.shape)\n",
    "        # print(\"S_p_n shape:\", S_p_n.shape)\n",
    "        # print(\"S_p_p shape:\", S_p_p.shape)\n",
    "        # print(\"grad_output shape:\", grad_output.shape)\n",
    "\n",
    "\n",
    "        l, k1, k2, p = ctx.l, ctx.k1, ctx.k2, ctx.p\n",
    "\n",
    "        S_n_n = S_n_n.unsqueeze(0)  # [1, C, H, W]\n",
    "        S_n_p = S_n_p.unsqueeze(0)\n",
    "        S_p_n = S_p_n.unsqueeze(0)\n",
    "        S_p_p = S_p_p.unsqueeze(0)\n",
    "        Gi = Gi.unsqueeze(0)\n",
    "        \n",
    "        # Gradient mask and kernel\n",
    "        relu_mask = (input > 0).float()\n",
    "        kernel = torch.where(input*grad_output > 0,\n",
    "            torch.zeros_like(input) if l*k1 == 0 else l / (1 + torch.abs(input) / (l * k1)),\n",
    "            torch.zeros_like(input) if l*k2 == 0 else l / (1 + torch.abs(input) / (l * k2)),\n",
    "        )\n",
    "\n",
    "        # Modulated gradient through activation\n",
    "        grad_input = relu_mask*grad_output\n",
    "        eventual_input = - torch.sign(input) * kernel * grad_output\n",
    "\n",
    "        eps = 1e-12\n",
    "        # Apply gating logic\n",
    "        gated_eventual_input = torch.where(\n",
    "            input < 0,\n",
    "            torch.where(\n",
    "                (S_n_n + S_n_p <= 0) | (eventual_input <= 0),\n",
    "                eventual_input,\n",
    "                eventual_input * (-S_n_n / (S_n_p + eps))\n",
    "            ),\n",
    "            torch.where(\n",
    "                (S_p_p + S_p_n >= 0) | (eventual_input >= 0),\n",
    "                eventual_input,\n",
    "                eventual_input * (S_p_p / (-S_p_n + eps))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        S_n = S_n_n + S_n_p\n",
    "        S_n_c = S_n*(S_n < 0).float()\n",
    "        S_p = S_p_p + S_p_n\n",
    "        S_p_c = S_p*(S_p > 0).float()\n",
    "        \n",
    "        s = min(torch.sum(Gi*(S_n_c+ S_p_c))/(torch.sum(Gi*Gi)+ eps),0)\n",
    "        \n",
    "        gated_grad_input = grad_input *(1 - s)\n",
    "\n",
    "        grad_S_n_n = (((input < 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_n_p = (((input < 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_p_n = (((input > 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_p_p = (((input > 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "\n",
    "        return gated_grad_input + gated_eventual_input*p, grad_S_n_n, grad_S_n_p, grad_S_p_n, grad_S_p_p, eventual_input, None, None, None, None\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GEDReLU5(nn.Module):\n",
    "    def __init__(self, shape = None, l=0.01, k1=1, k2= 1.0, p=1.0):\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.p = p\n",
    "        self.is_GED = True\n",
    "\n",
    "        if shape != None:\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_p_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_p_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.S_p_n.is_GED = True\n",
    "            self.S_p_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        else:\n",
    "            self.S_n_n = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        # # Lazy init on first call\n",
    "        if self.S_n_n is None:\n",
    "            shape = input.shape[1:]  # Exclude batch dim\n",
    "            device = input.device\n",
    "            dtype = input.dtype\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_p_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_p_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.S_p_n.is_GED = True\n",
    "            self.S_p_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        return GEDReLU5Function.apply(input, self.S_n_n, self.S_n_p, self.S_p_n, self.S_p_p, self.Gi, self.l, self.k1, self.k2, self.p)\n",
    "        # return GEDReLUFunction.apply(input)\n",
    "\n",
    "    def update_s(self, beta=0.9):\n",
    "        \"\"\"\n",
    "        Manual update rule, called every epoch.\n",
    "        Implements EMA-like update:\n",
    "        S := beta * S + (1 - beta) * grad_S\n",
    "        \"\"\"\n",
    "        for param in [self.S_n_n, self.S_n_p, self.S_p_n, self.S_p_p, self.Gi]:\n",
    "            if param.grad is not None:\n",
    "                param.data.mul_(beta).add_((1 - beta) * param.grad.data)\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()\n",
    "\n",
    "    def get_s_buffers(self):\n",
    "        return {\n",
    "            \"S_n_n\": self.S_n_n,\n",
    "            \"S_n_p\": self.S_n_p,\n",
    "            \"S_p_n\": self.S_p_n,\n",
    "            \"S_p_p\": self.S_p_p\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff20d2b-329d-41e9-b699-22bed7e890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "class GEDGELUFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, S_n_n, S_n_p, Gi, l, k1, k2, p = 1):\n",
    "        ctx.l = l\n",
    "        ctx.k1 = k1 \n",
    "        ctx.k2 = k2\n",
    "        ctx.p = p\n",
    "        ctx.save_for_backward(input, S_n_n, S_n_p, Gi)\n",
    "        return F.gelu(input)\n",
    "    # @staticmethod\n",
    "    # def forward(ctx, input):\n",
    "    #     # ctx.l = l\n",
    "    #     # ctx.k = k\n",
    "    #     # ctx.p = p\n",
    "    #     ctx.save_for_backward(input)\n",
    "    #     return F.relu(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, S_n_n, S_n_p, Gi = ctx.saved_tensors\n",
    "\n",
    "        # print(\"---input shape:\", input.shape)\n",
    "        # print(\"S_n_n shape:\", S_n_n.shape)\n",
    "        # print(\"S_n_p shape:\", S_n_p.shape)\n",
    "        # print(\"S_p_n shape:\", S_p_n.shape)\n",
    "        # print(\"S_p_p shape:\", S_p_p.shape)\n",
    "        # print(\"grad_output shape:\", grad_output.shape)\n",
    "\n",
    "\n",
    "        l, k1, k2, p = ctx.l, ctx.k1, ctx.k2, ctx.p\n",
    "\n",
    "        S_n_n = S_n_n.unsqueeze(0)  # [1, C, H, W]\n",
    "        S_n_p = S_n_p.unsqueeze(0)\n",
    "        Gi = Gi.unsqueeze(0)\n",
    "        \n",
    "        # Gradient mask and kernel\n",
    "        gelu_mask = 0.5*(torch.erf(input/np.sqrt(2))+1) + input/np.sqrt(2*np.pi)*torch.exp(-input*input/2)\n",
    "        kernel = torch.where(input*grad_output > 0,\n",
    "            torch.zeros_like(input) if l*k1 == 0 else l / (1 + torch.abs(input) / (l * k1)),\n",
    "            torch.zeros_like(input) if l*k2 == 0 else l / (1 + torch.abs(input) / (l * k2)),\n",
    "        )\n",
    "\n",
    "        # Modulated gradient through activation\n",
    "        grad_input = gelu_mask*grad_output\n",
    "        eventual_input = (input < 0).float() * kernel * grad_output\n",
    "\n",
    "        eps = 1e-12\n",
    "        # Apply gating logic\n",
    "        gated_eventual_input = torch.where((eventual_input <= 0)| (S_n_n + S_n_p <= 0),\n",
    "                    eventual_input,\n",
    "                    eventual_input * (-S_n_n / (S_n_p + eps)),\n",
    "                )\n",
    "\n",
    "        S_n = S_n_n + S_n_p\n",
    "        S_n_c = S_n*(S_n< 0).float()\n",
    "        s = min(torch.sum(Gi*S_n_c)/(torch.sum(Gi*Gi)+ eps),0)\n",
    "        \n",
    "        gated_grad_input = grad_input *(1 - s)\n",
    "        # gated_grad_input = grad_input *( 1 + torch.where((S_n_n + S_n_p < 0) & (Gi > 0), -(S_n_n + S_n_p)/Gi, 0))\n",
    "\n",
    "        grad_S_n_n = (((input < 0) & (eventual_input < 0)).float() * eventual_input).sum(dim = 0)\n",
    "        grad_S_n_p = (((input < 0) & (eventual_input > 0)).float() * eventual_input).sum(dim = 0)\n",
    "\n",
    "        return gated_grad_input + gated_eventual_input, grad_S_n_n, grad_S_n_p, grad_input , None, None, None, None, None\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GEDGELU(nn.Module):\n",
    "    def __init__(self, shape = None, l=0.01, k1=1, k2 = 1, p=1.0):\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.p = p\n",
    "        self.is_GED = True\n",
    "\n",
    "        if shape != None:\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        else:\n",
    "            self.S_n_n = None\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        # # Lazy init on first call\n",
    "        if self.S_n_n is None:\n",
    "            shape = input.shape[1:]  # Exclude batch dim\n",
    "            device = input.device\n",
    "            dtype = input.dtype\n",
    "            self.S_n_n = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_p = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.Gi = nn.Parameter(torch.zeros(shape, device=device, dtype=dtype), requires_grad=True)\n",
    "            self.S_n_n.is_GED = True\n",
    "            self.S_n_p.is_GED = True\n",
    "            self.Gi.is_GED = True\n",
    "        return GEDGELUFunction.apply(input, self.S_n_n, self.S_n_p, self.Gi, self.l, self.k1, self.k2, self.p)\n",
    "        # return GEDReLUFunction.apply(input)\n",
    "\n",
    "    def update_s(self, beta=0.9):\n",
    "        \"\"\"\n",
    "        Manual update rule, called every epoch.\n",
    "        Implements EMA-like update:\n",
    "        S := beta * S + (1 - beta) * grad_S\n",
    "        \"\"\"\n",
    "        for param in [self.S_n_n, self.S_n_p, self.Gi]:\n",
    "            if param.grad is not None:\n",
    "                param.data.mul_(beta).add_((1 - beta) * param.grad.data)\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()\n",
    "\n",
    "    def get_s_buffers(self):\n",
    "        return {\n",
    "            \"S_n_n\": self.S_n_n,\n",
    "            \"S_n_p\": self.S_n_p,\n",
    "            \"S_p_n\": self.S_p_n,\n",
    "            \"S_p_p\": self.S_p_p\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a182d2ba-f3ce-4024-864b-f90070d604bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEDCNN(nn.Module):\n",
    "    def __init__(self, l=0.01, k1=5.0, k2 = 1.0, act_class = GEDReLU,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.relu4 = act_class( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layerv\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        for module in self.children():\n",
    "            if hasattr(module,\"is_GED\"):\n",
    "                module.update_s(beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = self.pool(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8811bd95-3bbb-4f80-8fda-d1739ade442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEDGELUCNN(nn.Module):\n",
    "    def __init__(self, l=0.01, k1=5.0, k2 = 1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.relu4 = GEDGELU( l=l, k1=k1, k2=k2)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layerv\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        for module in self.children():\n",
    "            if hasattr(module,\"is_GED\"):\n",
    "                module.update_s(beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = self.pool(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29aec455-52bd-4ab6-b916-465cab5a96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation_fn=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.activation = activation_fn\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in [self.fc2]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='linear')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in [self.conv1,self.conv2,self.conv3,self.fc1]:\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = self.pool(self.activation(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def update_s(self,beta = 0.99):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e26d9b-e8ba-4f51-b0d7-b182f601d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7597c441-7792-437d-b8fe-805c999ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Train import train_and_evaluate, validate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67b57d7-eebb-4015-81b3-8ef4757a431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_ged(network, train_loader, val_loader, epochs=10, lr=0.001,beta = 0.99, log_every=100, device='cpu',\n",
    "                       save_path = None, save_every = 5, use_ged = True,\n",
    "                       logger = None):\n",
    "    model = network.to(device)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: not hasattr(p,\"is_GED\"), model.parameters()), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    logs = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        grad_norms = []\n",
    "        weight_updates = []\n",
    "        \n",
    "        running_loss = deque(maxlen=50)  # For smooth display\n",
    "        running_acc = deque(maxlen=50)\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "        \n",
    "            # Gradients and updates\n",
    "            total_norm = 0\n",
    "            weight_update_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    total_norm += p.grad.data.norm(2).item() ** 2\n",
    "                    weight_update_norm += (lr * p.grad.data).norm(2).item() ** 2\n",
    "        \n",
    "            grad_norms.append(np.sqrt(total_norm))\n",
    "            weight_updates.append(np.sqrt(weight_update_norm))\n",
    "        \n",
    "            optimizer.step()\n",
    "            if use_ged:\n",
    "                model.update_s(beta)\n",
    "        \n",
    "            batch_size = inputs.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total += batch_size\n",
    "        \n",
    "            batch_acc = (outputs.argmax(1) == labels).float().mean().item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "            # if batch_idx % log_every == 0:\n",
    "            #     logs['batches'].append({\n",
    "            #         'epoch': epoch,\n",
    "            #         'batch_idx': batch_idx,\n",
    "            #         'loss': loss.item(),\n",
    "            #         'acc': batch_acc,\n",
    "            #         'grad_norm': grad_norms[-1],\n",
    "            #         'weight_update_norm': weight_updates[-1],\n",
    "            #         'samples_seen': total\n",
    "            #     })\n",
    "        \n",
    "            # Track running stats for display\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(batch_acc)\n",
    "        \n",
    "            if batch_idx % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{np.mean(running_loss):.4f}',\n",
    "                    'acc': f'{np.mean(running_acc) * 100:.2f}%',\n",
    "                    'grad_norm': f'{grad_norms[-1]:.2f}'\n",
    "                })\n",
    "\n",
    "        logs['train_loss'].append(total_loss / total)\n",
    "        logs['train_acc'].append(correct / total)\n",
    "        logs['train_grad_norm'].append(np.mean(grad_norms))\n",
    "        logs['train_weight_update_norm'].append(np.mean(weight_updates))\n",
    "        \n",
    "        val_loss, val_acc = validate_model(model,val_loader,device)\n",
    "        \n",
    "        logs['val_loss'].append(val_loss)\n",
    "        logs['val_acc'].append(val_acc)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {logs['train_loss'][-1]:.4f} | \"\n",
    "              f\"Train Acc: {logs['train_acc'][-1]*100:.2f}% | \"\n",
    "              f\"Val Acc: {logs['val_acc'][-1]*100:.2f}%\")\n",
    "    return logs, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef305a7-ca00-4e57-a585-5be4120a65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = dict()\n",
    "model_data = dict()\n",
    "def insert_log_data(key,data):\n",
    "    if key not in log_data:\n",
    "        log_data[key] = []\n",
    "    log_data[key].append(data)\n",
    "def insert_model_data(key,data):\n",
    "    if key not in log_data:\n",
    "        model_data[key] = []\n",
    "    model_data[key].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22e3e199-29cc-4766-9fc4-9ee9ea92134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FileUtils\n",
    "importlib.reload(FileUtils)\n",
    "from FileUtils import load_log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36ff83f3-cb1b-49eb-9693-30e84f442a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/martinlu/Desktop/GitHub/ai/GradientModulation'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a3f2ba6-8860-4aec-a466-85148158251d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84bebcef-2d80-4156-be6f-d830295d9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import GEDResNet\n",
    "importlib.reload(GEDResNet)\n",
    "from GEDResNet import GEDResNet18, initialize_ged_resnet\n",
    "from ResNet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "915400de-b5bf-4356-aed9-dca1daffdb2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.6044 | Train Acc: 42.55% | Val Acc: 49.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.1996 | Train Acc: 57.17% | Val Acc: 56.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 1.0480 | Train Acc: 63.18% | Val Acc: 65.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.9478 | Train Acc: 66.85% | Val Acc: 65.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.8754 | Train Acc: 69.46% | Val Acc: 68.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.8212 | Train Acc: 71.33% | Val Acc: 71.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7745 | Train Acc: 73.13% | Val Acc: 70.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.7401 | Train Acc: 74.13% | Val Acc: 74.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.7099 | Train Acc: 75.47% | Val Acc: 73.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6796 | Train Acc: 76.56% | Val Acc: 73.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.6568 | Train Acc: 77.11% | Val Acc: 75.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.6431 | Train Acc: 77.47% | Val Acc: 75.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.6176 | Train Acc: 78.52% | Val Acc: 75.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.6019 | Train Acc: 79.19% | Val Acc: 76.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.5923 | Train Acc: 79.31% | Val Acc: 77.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5715 | Train Acc: 80.12% | Val Acc: 77.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5594 | Train Acc: 80.54% | Val Acc: 76.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.5553 | Train Acc: 80.48% | Val Acc: 77.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.5361 | Train Acc: 81.30% | Val Acc: 78.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.5296 | Train Acc: 81.54% | Val Acc: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.5120 | Train Acc: 82.06% | Val Acc: 78.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.5044 | Train Acc: 82.43% | Val Acc: 78.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.5003 | Train Acc: 82.49% | Val Acc: 78.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.4890 | Train Acc: 82.90% | Val Acc: 78.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.4789 | Train Acc: 83.18% | Val Acc: 77.62%\n"
     ]
    }
   ],
   "source": [
    "#Test clipped gmodrelu\n",
    "import GModReLU\n",
    "import importlib\n",
    "importlib.reload(GModReLU)\n",
    "from GModReLU import GModReLU, GModReLUFunction\n",
    "loaded_model = CNN(GModReLU(l = l_val, k = k_val, kernel_type = [\"nonscale\",\"clip\"]))\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "l_val = 0.02\n",
    "k_val = 5.0\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gmrelu(nonscale,clip)\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8d5a856-c8a9-4136-bcb3-c5fbd0592d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GEDReLU3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "714af762-26bf-4275-b51e-1500d21271fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'GEDReLU4' from '/Users/martinlu/Desktop/GitHub/ai/GradientModulation/GEDReLU4.py'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GEDReLU4\n",
    "importlib.reload(GEDReLU4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "147c87dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.3957 | Train Acc: 49.36% | Val Acc: 59.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.8972 | Train Acc: 68.08% | Val Acc: 70.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.7159 | Train Acc: 74.94% | Val Acc: 72.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.6011 | Train Acc: 79.16% | Val Acc: 78.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.5262 | Train Acc: 81.75% | Val Acc: 79.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.4708 | Train Acc: 83.64% | Val Acc: 81.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.3896 | Train Acc: 86.67% | Val Acc: 82.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.3505 | Train Acc: 87.90% | Val Acc: 86.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.3186 | Train Acc: 89.02% | Val Acc: 85.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.3037 | Train Acc: 89.60% | Val Acc: 85.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.2713 | Train Acc: 90.65% | Val Acc: 85.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.2595 | Train Acc: 90.96% | Val Acc: 87.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.2323 | Train Acc: 91.99% | Val Acc: 87.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.2170 | Train Acc: 92.52% | Val Acc: 88.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.2004 | Train Acc: 92.97% | Val Acc: 88.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.1863 | Train Acc: 93.49% | Val Acc: 88.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.1712 | Train Acc: 94.00% | Val Acc: 87.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.1663 | Train Acc: 94.10% | Val Acc: 89.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.1460 | Train Acc: 94.91% | Val Acc: 89.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.1372 | Train Acc: 95.07% | Val Acc: 88.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.1350 | Train Acc: 95.26% | Val Acc: 88.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.1220 | Train Acc: 95.71% | Val Acc: 89.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.1144 | Train Acc: 96.03% | Val Acc: 89.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.1110 | Train Acc: 96.02% | Val Acc: 90.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.1018 | Train Acc: 96.39% | Val Acc: 89.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.0972 | Train Acc: 96.61% | Val Acc: 90.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.0959 | Train Acc: 96.61% | Val Acc: 89.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.0858 | Train Acc: 97.00% | Val Acc: 90.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.0886 | Train Acc: 96.93% | Val Acc: 90.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.0739 | Train Acc: 97.44% | Val Acc: 89.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.0730 | Train Acc: 97.40% | Val Acc: 90.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.0714 | Train Acc: 97.48% | Val Acc: 90.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.0704 | Train Acc: 97.54% | Val Acc: 90.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.0662 | Train Acc: 97.69% | Val Acc: 90.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.0627 | Train Acc: 97.76% | Val Acc: 90.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.0619 | Train Acc: 97.80% | Val Acc: 90.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.0582 | Train Acc: 97.94% | Val Acc: 90.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.0572 | Train Acc: 97.99% | Val Acc: 91.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.0567 | Train Acc: 98.00% | Val Acc: 91.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.0537 | Train Acc: 98.18% | Val Acc: 91.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.0509 | Train Acc: 98.22% | Val Acc: 91.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.0475 | Train Acc: 98.29% | Val Acc: 90.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.0449 | Train Acc: 98.44% | Val Acc: 91.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.0458 | Train Acc: 98.40% | Val Acc: 90.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 0.0479 | Train Acc: 98.32% | Val Acc: 91.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 0.0494 | Train Acc: 98.31% | Val Acc: 90.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 0.0409 | Train Acc: 98.54% | Val Acc: 91.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 0.0392 | Train Acc: 98.65% | Val Acc: 90.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 0.0411 | Train Acc: 98.58% | Val Acc: 90.44%\n"
     ]
    }
   ],
   "source": [
    "#Testting RELU\n",
    "loaded_model = ResNet18().apply(initialize_ged_resnet)\n",
    "# loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=50,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    use_ged = False,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[resnet]relu\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f906a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDResNet18(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val, act_class \u001b[38;5;241m=\u001b[39m GEDReLU7\u001b[38;5;241m.\u001b[39mGEDReLU)\u001b[38;5;241m.\u001b[39mapply(initialize_ged_resnet)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ged\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[resnet]relu\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k1_val,k2_val),log)\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:277\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import GEDReLU7\n",
    "importlib.reload(GEDReLU7)\n",
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.1\n",
    "loaded_model = GEDResNet18(l = l_val, k1 = k1_val, k2 = k2_val, act_class = GEDReLU7.GEDReLU).apply(initialize_ged_resnet)\n",
    "# loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=50,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    use_ged = False,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[resnet]relu\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81ec525b-a059-406d-b693-345365dea46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 32])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.layer1[0].act1.S_n_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import GEDReLU7\n",
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.1\n",
    "loaded_model = GEDResNet18(l = l_val, k1 = k1_val, k2 = k2_val, act_class = GEDReLU7.GEDReLU).apply(initialize_ged_resnet)\n",
    "# loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=50,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    use_ged = False,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[resnet]relu\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c414dc-0538-4ebc-ae29-c9b851de0883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "00961593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[347], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val, act_class \u001b[38;5;241m=\u001b[39m GEDReLU5)\n\u001b[1;32m      7\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_untrained1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 8\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mged5\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k1_val,k2_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ged:\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     44\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size\n",
      "Cell \u001b[0;32mIn[299], line 36\u001b[0m, in \u001b[0;36mGEDCNN.update_s\u001b[0;34m(self, beta)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_GED\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 36\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[309], line 139\u001b[0m, in \u001b[0;36mGEDReLU5.update_s\u001b[0;34m(self, beta)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS_n_n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS_n_p, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS_p_n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS_p_p, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGi]:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[1;32m    141\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mzero_()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testting GED5\n",
    "#Conclusion: Not significantly better\n",
    "l_val = 0.02\n",
    "k1_val = 7.5\n",
    "k2_val = 0.5\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val, act_class = GEDReLU5)\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=11,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"ged5\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d1047e02-4faf-453c-80b0-5529910c09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 1.4705 | Train Acc: 47.50% | Val Acc: 57.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 1.0632 | Train Acc: 62.52% | Val Acc: 63.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[353], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDGELUCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val)\n\u001b[1;32m      6\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_untrained1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 7\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgedgelu\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k1_val,k2_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[351], line 51\u001b[0m, in \u001b[0;36mGEDGELUFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     49\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Apply gating logic\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m gated_eventual_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43meventual_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_n_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS_n_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43meventual_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43meventual_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mS_n_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_n_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m S_n \u001b[38;5;241m=\u001b[39m S_n_n \u001b[38;5;241m+\u001b[39m S_n_p\n\u001b[1;32m     57\u001b[0m S_n_c \u001b[38;5;241m=\u001b[39m S_n\u001b[38;5;241m*\u001b[39m(S_n\u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testting new clipped dged GELU with new kernel \n",
    "l_val = 0.02\n",
    "k1_val = 7.5\n",
    "k2_val = 1.0\n",
    "loaded_model = GEDGELUCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=5,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gedgelu\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248921e-5e56-46ed-ae53-9a72cd82d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "98ccd4cb-fdea-4aeb-a882-c66a38b2c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4848653153101603,\n",
       " 1.0595959030363296,\n",
       " 0.9035886674775018,\n",
       " 0.8083200914700825,\n",
       " 0.7512857806735569,\n",
       " 0.7062555783238675,\n",
       " 0.6603865298165216,\n",
       " 0.636535771730211,\n",
       " 0.6080090568860372,\n",
       " 0.5905408076816135,\n",
       " 0.5694922658390469,\n",
       " 0.5512248729652829,\n",
       " 0.5357832288821538,\n",
       " 0.5198717035690943,\n",
       " 0.5023744517220391,\n",
       " 0.4949553271823459,\n",
       " 0.4873157972070906,\n",
       " 0.4778727073113124,\n",
       " 0.4646957883516947,\n",
       " 0.4595615298377143,\n",
       " 0.4511569716135661,\n",
       " 0.44614050909678143,\n",
       " 0.4364197584470113,\n",
       " 0.4325642474386427,\n",
       " 0.4244985025617811]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data[('ged4', 0.02, 7.5, 0.1)][1]['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "127aede4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.5801 | Train Acc: 43.58% | Val Acc: 51.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.2040 | Train Acc: 56.97% | Val Acc: 58.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 1.0430 | Train Acc: 63.01% | Val Acc: 63.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.9478 | Train Acc: 66.89% | Val Acc: 68.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.8820 | Train Acc: 69.12% | Val Acc: 68.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.8245 | Train Acc: 71.15% | Val Acc: 69.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7818 | Train Acc: 72.77% | Val Acc: 71.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.7408 | Train Acc: 73.97% | Val Acc: 70.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.7260 | Train Acc: 74.71% | Val Acc: 73.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6964 | Train Acc: 75.87% | Val Acc: 74.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.6773 | Train Acc: 76.35% | Val Acc: 75.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.6525 | Train Acc: 77.41% | Val Acc: 75.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.6334 | Train Acc: 77.96% | Val Acc: 74.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.6165 | Train Acc: 78.58% | Val Acc: 74.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.6027 | Train Acc: 78.91% | Val Acc: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5918 | Train Acc: 79.34% | Val Acc: 76.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5805 | Train Acc: 79.68% | Val Acc: 77.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.5655 | Train Acc: 80.23% | Val Acc: 77.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.5549 | Train Acc: 80.75% | Val Acc: 77.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.5534 | Train Acc: 80.61% | Val Acc: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.5391 | Train Acc: 81.28% | Val Acc: 78.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.5293 | Train Acc: 81.52% | Val Acc: 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.5224 | Train Acc: 81.76% | Val Acc: 77.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.5161 | Train Acc: 82.21% | Val Acc: 78.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.5088 | Train Acc: 82.23% | Val Acc: 79.36%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"relu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0b418cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.5255 | Train Acc: 45.46% | Val Acc: 56.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 | Train Loss: 1.1173 | Train Acc: 60.34% | Val Acc: 58.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 | Train Loss: 0.9623 | Train Acc: 65.89% | Val Acc: 68.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 | Train Loss: 0.8570 | Train Acc: 69.96% | Val Acc: 69.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 | Train Loss: 0.7964 | Train Acc: 71.95% | Val Acc: 71.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 | Train Loss: 0.7401 | Train Acc: 74.11% | Val Acc: 72.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 | Train Loss: 0.7033 | Train Acc: 75.38% | Val Acc: 73.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 | Train Loss: 0.6707 | Train Acc: 76.53% | Val Acc: 74.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 | Train Loss: 0.6398 | Train Acc: 77.68% | Val Acc: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 | Train Loss: 0.6161 | Train Acc: 78.47% | Val Acc: 75.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 | Train Loss: 0.5971 | Train Acc: 79.02% | Val Acc: 76.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 | Train Loss: 0.5782 | Train Acc: 79.72% | Val Acc: 77.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 | Train Loss: 0.5629 | Train Acc: 80.35% | Val Acc: 77.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 | Train Loss: 0.5511 | Train Acc: 80.73% | Val Acc: 77.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 | Train Loss: 0.5269 | Train Acc: 81.54% | Val Acc: 77.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 | Train Loss: 0.5115 | Train Acc: 82.08% | Val Acc: 78.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 | Train Loss: 0.5055 | Train Acc: 82.18% | Val Acc: 78.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 | Train Loss: 0.4950 | Train Acc: 82.62% | Val Acc: 78.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 | Train Loss: 0.4895 | Train Acc: 82.76% | Val Acc: 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 | Train Loss: 0.4755 | Train Acc: 83.17% | Val Acc: 78.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 | Train Loss: 0.4653 | Train Acc: 83.69% | Val Acc: 79.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 | Train Loss: 0.4523 | Train Acc: 84.08% | Val Acc: 78.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 | Train Loss: 0.4431 | Train Acc: 84.46% | Val Acc: 78.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 | Train Loss: 0.4388 | Train Acc: 84.52% | Val Acc: 79.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 | Train Loss: 0.4330 | Train Acc: 84.84% | Val Acc: 79.06%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = CNN(torch.nn.GELU())\n",
    "loaded_model.load_state_dict(torch.load('cnn_untrained1.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=25,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"gelu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a7108d6-1ca7-42d0-b1ee-66d82b9f178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN().state_dict(), \"cnn_untrained1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6727c088-8e64-4198-80a3-7951548e7f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.4478 | Train Acc: 84.58% | Val Acc: 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val)\n\u001b[1;32m      5\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 6\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pt]dged(0.9)\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k1_val,k2_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 47\u001b[0m, in \u001b[0;36mGEDReLUFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Modulated gradient through activation\u001b[39;00m\n\u001b[1;32m     46\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m relu_mask\u001b[38;5;241m*\u001b[39mgrad_output\n\u001b[0;32m---> 47\u001b[0m eventual_input \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m kernel \u001b[38;5;241m*\u001b[39m grad_output\n\u001b[1;32m     49\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Apply gating logic\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.05\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    beta = 0.9,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]dged(0.9)\",l_val,k1_val,k2_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a9a2ccfb-0818-493b-b94f-ea79ba843632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 | Train Loss: 0.4429 | Train Acc: 84.50% | Val Acc: 84.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6 | Train Loss: 0.4382 | Train Acc: 84.72% | Val Acc: 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6 | Train Loss: 0.4305 | Train Acc: 84.87% | Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6 | Train Loss: 0.4176 | Train Acc: 85.37% | Val Acc: 84.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6 | Train Loss: 0.4267 | Train Acc: 85.15% | Val Acc: 83.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6 | Train Loss: 0.4129 | Train Acc: 85.48% | Val Acc: 83.48%\n"
     ]
    }
   ],
   "source": [
    "#Testing on pretrained to 35 epochs (focusing in on a particular training regime)\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=6,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]relu\",),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4268fbfd-fc2b-43e5-b30f-a354d867e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35 | Train Loss: 0.4446 | Train Acc: 84.61% | Val Acc: 83.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35 | Train Loss: 0.4368 | Train Acc: 84.80% | Val Acc: 85.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35 | Train Loss: 0.4320 | Train Acc: 84.89% | Val Acc: 84.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35 | Train Loss: 0.4225 | Train Acc: 85.26% | Val Acc: 84.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35 | Train Loss: 0.4145 | Train Acc: 85.57% | Val Acc: 84.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35 | Train Loss: 0.4151 | Train Acc: 85.55% | Val Acc: 82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35 | Train Loss: 0.4108 | Train Acc: 85.57% | Val Acc: 84.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m GEDCNN(l \u001b[38;5;241m=\u001b[39m l_val, k1 \u001b[38;5;241m=\u001b[39m k1_val, k2 \u001b[38;5;241m=\u001b[39m k2_val)\n\u001b[1;32m      6\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_pretrained.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 7\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pt]bged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[183], line 63\u001b[0m, in \u001b[0;36mGEDReLUFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     60\u001b[0m gated_grad_input \u001b[38;5;241m=\u001b[39m grad_input \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m s)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# gated_grad_input = grad_input *( 1 + torch.where((S_n_n + S_n_p < 0) & (Gi > 0), -(S_n_n + S_n_p)/Gi, 0))\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m grad_S_n_n \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43meventual_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m eventual_input)\u001b[38;5;241m.\u001b[39msum(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     64\u001b[0m grad_S_n_p \u001b[38;5;241m=\u001b[39m (((\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (eventual_input \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m eventual_input)\u001b[38;5;241m.\u001b[39msum(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gated_grad_input \u001b[38;5;241m+\u001b[39m gated_eventual_input, grad_S_n_n, grad_S_n_p, grad_input , \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testing GED on pretrained to 35 epochs (focusing in on a particular training regime)\n",
    "l_val = 0.02\n",
    "k1_val = 1.0\n",
    "k2_val = 0.0\n",
    "loaded_model = GEDCNN(l = l_val, k1 = k1_val, k2 = k2_val)\n",
    "loaded_model.load_state_dict(torch.load('cnn_pretrained.pt', weights_only=True, map_location=torch.device('cpu')))\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = loaded_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=35,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[pt]bged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ef8659ae-4b93-4b42-b1d2-009443de84dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1503e-07, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(model.relu1.S_n_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5a4b3876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[278], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m l_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      3\u001b[0m k_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGEDResNet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialize_ged_resnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[resnet]ged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[54], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     21\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ai/GradientModulation/GEDResNet.py:114\u001b[0m, in \u001b[0;36mGEDResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m--> 114\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m    116\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(out)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ai/GradientModulation/GEDResNet.py:35\u001b[0m, in \u001b[0;36mGEDBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n\u001b[1;32m     37\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test GEDResNet\n",
    "l_val = 0.01\n",
    "k_val = 1.0\n",
    "log, model = train_and_evaluate_ged(\n",
    "    network = GEDResNet18().apply(initialize_ged_resnet),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=15,          # or however many you want\n",
    "    lr=0.001,           # or your preferred LR\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "insert_log_data((\"[resnet]ged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf11604-5fe2-4d94-9f79-a6691f46ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1a15156-432b-425b-a09a-afec5efdf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m l_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      3\u001b[0m k_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m log, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGEDCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ml_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or however many you want\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# or your preferred LR\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m insert_log_data((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mged\u001b[39m\u001b[38;5;124m\"\u001b[39m,l_val,k_val),log)\n",
      "Cell \u001b[0;32mIn[54], line 26\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ged\u001b[0;34m(network, train_loader, val_loader, epochs, lr, beta, log_every, device, save_path, save_every, use_ged, logger)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Gradients and updates\u001b[39;00m\n\u001b[1;32m     29\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchenv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    l_val = 0.01\n",
    "    k_val = 5.0\n",
    "    log, model = train_and_evaluate_ged(\n",
    "        network = GEDCNN(l = l_val, k = k_val),\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=2,          # or however many you want\n",
    "        lr=0.001,           # or your preferred LR\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    insert_log_data((\"ged\",l_val,k_val),log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "626506d6-9e6a-4d59-a917-3369d5dda3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('relu',), ('gmrelu(nonscale)', 0.02, 1.0), ('gmrelu(nonscale,clip)', 0.02, 1.0), ('dged', 0.02, 1.0, 0.5), ('dged', 0.02, 1.0, 0.1), ('dged', 0.02, 1.0, 0.0), ('dged(0.9)', 0.02, 1.0, 0.0), ('ged', 0.02, 1.0, 0.0), ('ged2', 0.02, 1.0, 0.0), ('ged4', 0.02, 1.0, 0.0), ('[pt]relu',), ('ged4', 0.02, 5.0, 0.1), ('gmrelu(nonscale,clip)', 0.02, 5.0), ('gelu',), ('ged4', 0.02, 7.5, 0.1), ('ged5', 0.02, 7.5, 0.5), ('ged4', 0.02, 7.5, 0.5), ('gedgelu(ker2)', 0.02, 7.5, 0.1), ('gedgelu', 0.02, 7.5, 0.1), ('[pt]ged4', 0.02, 7.5, 0.5)])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e9131ce-ecd5-45c1-81a6-27ffdd6890ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('[resnet]ged4', 0.02, 7.5, 0.5), ('[resnet]relu', 0.02, 7.5, 0.5), ('[resnet]ged4', 0.02, 1.0, 0.5), ('[resnet]ged4', 0.02, 1.0, 0.1), ('[resnet]ged3', 0.02, 1.0, 0.1), ('[resnet]relu', 0.02, 1.0, 0.1), ('[resnet]ged3', 0.02, 1.0, 1.0), ('[resnet]ged6', 0.02, 1.0, 1.0)])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = load_log_data(\"logs/log_data_bged_relu.pkl\")\n",
    "log_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bc6b857b-6c06-4855-b592-5dbc4d315dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss shape: (50,)\n",
      "loss shape: (50,)\n",
      "loss shape: (50,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import Figures\n",
    "importlib.reload(Figures)\n",
    "from Figures import log_data_with_k, plot_logs_k, plot_logs_ke, log_data_with_l , plot_logs_k_col, log_data_with_activations\n",
    "prop = \"train_loss\"\n",
    "plot_logs_k_col(*log_data_with_activations([ ('[resnet]relu', 0.02, 1.0, 0.1), ('[resnet]ged3', 0.02, 1.0, 1.0), ('[resnet]ged6', 0.02, 1.0, 1.0)],\n",
    "                                           [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\",\"brown\",\"pink\"], log_data),\n",
    "                file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,50), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',),('ged4', 0.02, 1.0, 0.0),('ged4', 0.02, 5.0, 0.1), ('gmrelu(nonscale,clip)', 0.02, 5.0),(\"gelu\",),('ged4', 0.02, 7.5, 0.1)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (5,25), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',),('gmrelu(nonscale,clip)', 0.02, 1.0),('gmrelu(nonscale)', 0.02, 1.0), ('ged2', 0.02, 1.0, 0.0),('ged4', 0.02, 1.0, 0.0)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\",\"yellow\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (1,6), y_scale = \"linear\")\n",
    "# plot_logs_k_col(*log_data_with_activations([('relu',), ('gmrelu(nonscale)', 0.02, 1.0),('gmrelu(nonscale,clip)', 0.02, 1.0),('dged', 0.02, 1.0, 0.5),('dged', 0.02, 1.0, 0.1)\n",
    "#     , ('dged', 0.02, 1.0, 0.0)],\n",
    "#                                            [\"red\",\"cyan\",\"green\",\"blue\",\"purple\",\"orange\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (1,4), y_scale = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cb13ad2-6cad-45d9-8fad-d2fe5ffff02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5497b54-60f7-4b9c-b15d-aad32d13919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import Figures\n",
    "importlib.reload(Figures)\n",
    "from Figures import log_data_with_k, plot_logs_k, plot_logs_ke, log_data_with_l , plot_logs_k_col, log_data_with_activations\n",
    "prop = \"val_loss\"\n",
    "plot_logs_k_col(*log_data_with_activations([('[pt]relu',),('[pt]ged4', 0.02, 7.5, 0.5) ],[\"red\",\"orange\",\"blue\",\"purple\",], log_data),\n",
    "                file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,10), y_scale = \"log\")\n",
    "# plot_logs_k_col(*log_data_with_activations([ ('relu',), ('ged', 0.01, 5.0),('ged',0.01,1.0),('ged',0.01,0.5)],[\"red\",\"blue\",\"cyan\",\"green\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,5 ), y_scale = \"log\")\n",
    "# plot_logs_k_col(*log_data_with_activations([ ('relu',),('ged', 0.0, 5.0),('ged',0.005,5.0), ('ged', 0.01, 5.0),('ged',0.02,5.0)],[\"red\",\"orange\",\"purple\",\"blue\",\"cyan\"], log_data),\n",
    "#                 file_name = None,prop = prop, x_axis = 'epoch',i_cut = 10, e_range = (0,15), y_scale = \"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "8f95e9e8-c731-4de9-9906-f3eb526c0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('log_data_bged.pkl', 'wb') as file: \n",
    "    # A new file will be created \n",
    "    pickle.dump(log_data, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf7f1e-98d4-4699-8fd2-54bb89729954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
